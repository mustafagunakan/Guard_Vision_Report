<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Guard Vision: Smarter AI for Theft Detection</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            line-height: 1.6;
            margin: 0;
            padding: 0;
            background-color: #f4f4f4;
            color: #333;
        }

        header {
            background: url('https://images.unsplash.com/photo-1589935447067-5531094415d1?q=80&w=2070&auto=format&fit=crop&ixlib=rb-4.0.3&ixid=M3wxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8fA%3D%3D') no-repeat center center/cover;
            color: white;
            padding: 4rem 2rem;
            text-align: center;
        }

        header h1 {
            margin: 0;
            font-size: 2.5rem;
        }

        header p {
            font-size: 1.2rem;
        }

        main {
            padding: 2rem;
            background: white;
            margin: 2rem auto;
            max-width: 800px;
            border-radius: 5px;
            box-shadow: 0 2px 5px rgba(0, 0, 0, 0.1);
        }

        section {
            margin-bottom: 2rem;
        }

        section h2 {
            margin-top: 0;
            color: #444;
        }

        .visuals img {
            max-width: 100%;
            height: auto;
            border: 1px solid #ddd;
            border-radius: 5px;
            margin-top: 1rem;
        }

        footer {
            text-align: center;
            padding: 1rem;
            background: #333;
            color: white;
        }
    </style>
</head>
<body>
    <header>
        <h1>Guard Vision: Smarter AI for Theft Detection</h1>
        <p>Redefining Front-Door AI Surveillance</p>
    </header>
    <main>
        <section>
            <h2>1. Project Overview</h2>
            <p><strong>Title:</strong> Guard Vision: Redefining Front-Door AI Surveillance</p>
            <p><strong>Objective:</strong> Develop an AI model capable of accurately detecting potential theft incidents in gardens and front doors, reducing irrelevant notifications and enhancing user trust.</p>
            <p><strong>Problem Statement:</strong> Current security camera systems rely heavily on motion detection, leading to frequent false alerts that reduce user trust and effectiveness. Despite advancements in AI, the market lacks accessible, intelligent theft detection solutions that process visual data efficiently and deliver accurate, context-aware alerts. This gap creates an opportunity to develop a smart security system that minimizes irrelevant triggers and enhances user experience with reliable real-time detection.</p>
            <p><strong>Team Composition:</strong></p>
            <ul>
                <li>Team Lead: Name</li>
                <li>Scrum Master: Name</li>
                <li>Product Designer: Name</li>
                <li>Data Scientists: Name 1, Name 2, â€¦ Name 7</li>
            </ul>
            <p><strong>Outcome:</strong> An educational and experimental project designed to address a significant market gap in home security solutions while enhancing team collaboration and technical expertise.</p>
            <div class="visuals">
                <img src="https://example.com/thumbnail.jpg" alt="Algorithm detecting a possible theft situation and sending alert messages to the user.">
                <p>Caption: Algorithm detecting a possible theft situation and sending alert messages to the user.</p>
            </div>
        </section>

        <section>
            <h2>2. Research and Model Assessment</h2>
            <p><strong>Research Phase:</strong> The team evaluated several AI detection models based on visual data to identify the most suitable option.</p>
            <p><strong>Models Tested and Member Contributions:</strong></p>
            <ul>
                <li>DETR</li>
                <li>DINO-R50</li>
                <li>DINO-SwinL</li>
                <li>YOLOv3/v5/v11</li>
                <li>Faster R-CNN</li>
                <li>ATSS</li>
                <li>RetinaNET</li>
            </ul>
            <p><strong>Evaluation Metrics:</strong> Speed, Accuracy, and Efficiency.</p>
            <p><strong>Team Dynamics:</strong> Collaborative reviews and documentation cycles ensured alignment and integration of findings.</p>
        </section>

        <section>
            <h2>3. Model Selection and Integration</h2>
            <p><strong>Chosen Model:</strong> YOLOv11</p>
            <p><strong>Reason for Selection:</strong> Best balance between speed, accuracy, and efficiency for real-time detection.</p>
            <p><strong>Tracking System Integration:</strong></p>
            <ul>
                <li>SORT</li>
                <li>DeepSORT</li>
                <li>ByteTrack</li>
            </ul>
            <p><strong>Challenges and Resolutions:</strong></p>
            <ul>
                <li><strong>Object ID Loss:</strong> Implemented a re-identification mechanism with persistent ID tracking.</li>
                <li><strong>Lag in Real-Time Detection:</strong> Optimized configurations to balance speed and accuracy.</li>
            </ul>
        </section>

        <section>
            <h2>4. Product Design and Vision</h2>
            <p>The product design reflects a structured plan that outlines the vision for the project's deployment, even though final implementation details remain under development. This framework demonstrates that a cohesive and actionable approach has been conceptualized, ensuring the project remains aligned with its goals.</p>
            <p><strong>User Side:</strong> Mobile and web applications featuring registration, authentication, camera integration, and real-time alerts.</p>
            <p><strong>Server Side:</strong> Scalable architecture with middleware, processing servers, and AI-powered models.</p>
            <div class="visuals">
                <img src="https://example.com/vision-map.jpg" alt="Product Vision Map.">
                <p>Caption: Product Vision Map.</p>
            </div>
        </section>

        <section>
            <h2>5. Project Management</h2>
            <p><strong>Role of Scrum Master:</strong> Coordinated sprints and facilitated collaboration between individual and group tasks.</p>
            <p><strong>Team Dynamics:</strong> Group activities such as brainstorming sessions and retrospectives improved teamwork and innovation.</p>
            <p>Role-specific contributions ensured clear accountability and efficient workflows.</p>
        </section>

        <section>
            <h2>6. Technologies and Tools Used</h2>
            <ul>
                <li>AI Models: YOLOv11 small/large</li>
                <li>Tracking Algorithms: DeepSORT, ByteTrack</li>
                <li>Tools: GitHub, Visual Studio, Trello, Discord</li>
                <li>Notification System Integration: Webhooks, API-based notifications</li>
            </ul>
        </section>

        <section>
            <h2>7. Notification System Integration</h2>
            <p><strong>Features:</strong> Smart notification triggers and advanced filtering to reduce false positives.</p>
            <p><strong>Testing:</strong> Simulated theft scenarios validated system reliability.</p>
        </section>

        <section>
            <h2>8. Use Cases and User Scenarios</h2>
            <p><strong>Potential Applications:</strong></p>
            <ul>
                <li>Residential gardens</li>
                <li>Small businesses</li>
            </ul>
            <p><strong>Example Scenarios:</strong></p>
            <ul>
                <li>Alerting on unauthorized object removal or theft</li>
                <li>Reducing irrelevant notifications caused by animals or passing vehicles</li>
            </ul>
            <p><strong>User Benefits:</strong> Fewer false alarms, leading to increased trust in the system. Real-time notifications ensure timely intervention.</p>
        </section>

        <section>
            <h2>9. Learning and Reflections</h2>
            <p>Hands-on experience in evaluating and integrating AI models.</p>
            <p>Practical exposure to resolving real-world challenges in tracking and notifications.</p>
        </section>

        <section>
            <h2>10. Next Steps</h2>
            <p>Refinement of tracking algorithms and further optimization.</p>
            <p>Testing with diverse datasets to improve robustness.</p>
            <p>Deploying the model for access via cloud services for beta testing.</p>
        </section>
    </main>
    <footer>
        <p>&copy; 2025 Guard Vision Project</p>
    </footer>
</body>
</html>
