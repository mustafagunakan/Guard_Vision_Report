<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Guard Vision: Smarter AI for Theft Detection</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            line-height: 1.6;
            margin: 0;
            padding: 0;
            background-color: #f4f4f4;
            color: #333;
        }

        header {
            background: url('https://images.unsplash.com/photo-1589935447067-5531094415d1?q=80&w=2070&auto=format&fit=crop&ixlib=rb-4.0.3&ixid=M3wxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8fA%3D%3D') no-repeat center center/cover;
            color: white;
            padding: 4rem 2rem;
            text-align: center;
        }

        header h1 {
            margin: 0;
            font-size: 2.5rem;
        }

        header p {
            font-size: 1.2rem;
        }

        main {
            padding: 2rem;
            background: white;
            margin: 2rem auto;
            max-width: 800px;
            border-radius: 5px;
            box-shadow: 0 2px 5px rgba(0, 0, 0, 0.1);
        }

        section {
            margin-bottom: 2rem;
        }

        section h2 {
            margin-top: 0;
            color: #444;
        }

        .visuals img {
            max-width: 100%;
            height: auto;
            border: 1px solid #ddd;
            border-radius: 5px;
            margin-top: 1rem;
        }

        footer {
            text-align: center;
            padding: 1rem;
            background: #333;
            color: white;
        }
    </style>
</head>
<body>
    <header>
        <h1>Guard Vision: Smarter AI for Theft Detection</h1>
        <p>Redefining Front-Door AI Surveillance</p>
    </header>
    <main>
        <section>
            <h2>1. Project Overview</h2>
            <p><strong>Title:</strong> Guard Vision: Redefining Front-Door AI Surveillance</p>
            <p><strong>Objective:</strong> Develop an AI model capable of accurately detecting potential theft incidents in gardens and front doors, reducing irrelevant notifications and enhancing user trust.</p>
            <p><strong>Problem Statement:</strong> Current security camera systems rely heavily on motion detection, leading to frequent false alerts that reduce user trust and effectiveness. Despite advancements in AI, the market lacks accessible, intelligent theft detection solutions that process visual data efficiently and deliver accurate, context-aware alerts. This gap creates an opportunity to develop a smart security system that minimizes irrelevant triggers and enhances user experience with reliable real-time detection.</p>
            <p><strong>Team Composition:</strong></p>
            <ul>
                <li>Team Lead: Name</li>
                <li>Scrum Master: Name</li>
                <li>Product Designer: Name</li>
                <li>Data Scientists: Name 1, Name 2, … Name 7</li>
            </ul>
            <p><strong>Outcome:</strong> An educational and experimental project designed to address a significant market gap in home security solutions while enhancing team collaboration and technical expertise.</p>
            <div class="visuals">
                <img src="" alt="Algorithm detecting a possible theft situation and sending alert messages to the user.">
                <p>Caption: Algorithm detecting a possible theft situation and sending alert messages to the user.</p>
            </div>
        </section>

        
        <section>
            <h2>2. Research and Model Assessment</h2>
            <p><strong>Research Phase:</strong> The team evaluated several AI detection models based on visual data to identify the most suitable option.</p>
            <p><strong>Models Tested and Member Contributions:</strong></p>
            <ul>
                <li><strong>DETR:</strong></li>
                <li><strong>DINO-R50:</strong></li>
                <li><strong>DINO-SwinL:</strong></li>
                <li><strong>YOLO V3/V5/V11:</strong></li>
                <li>Faster R-CNN</li>
                <li>ATSS</li>
                <li>RetinaNET</li>
            </ul>
            <p><strong>Evaluation Metrics:</strong></p>
            <ul>
                <li><strong>Speed:</strong> How quickly the model processed real-time data.</li>
                <li><strong>Accuracy:</strong> Precision in detecting objects in low quality video feeds.</li>
                <li><strong>Efficiency:</strong> Resource usage and feasibility for efficient cloud computing.</li>
            </ul>
            <p><strong>Team Dynamics:</strong></p>
            <ul>
                <li>Collaborative reviews during group discussions allowed members to share insights and refine the evaluation process.</li>
                <li>Documentation and feedback cycles ensured alignment and integration of individual findings.</li>
            </ul>
        </section>

          <section>
            <h2>3. Model Selection and Integration</h2>
            <p><strong>Chosen Model:</strong> YOLO V11</p>
            <p><strong>Reason for Selection:</strong> YOLOv11 was chosen for its superior balance of speed, accuracy, and efficiency, making it ideal for real-time object detection in dynamic environments.</p>
            <p><strong>Tracking System Integration:</strong></p>
            <p>Evaluation of tracking algorithms:</p>
            <ul>
                <li>SORT</li>
                <li>DeepSORT</li>
                <li>ByteTrack</li>
            </ul>
            <p>The system was integrated with ByteTrack, a highly effective tracking algorithm. ByteTrack was selected for its ability to handle both matched and unmatched detections, ensuring reliable tracking even for low-confidence objects. This robust tracking capability enhances consistency and accuracy in maintaining object identities across frames.</p>
            <p><strong>Challenges and Resolutions:</strong></p>
            <ul>
                <li><strong>Object ID Loss:</strong> Challenge: Objects temporarily leaving the frame or encountering occlusions often resulted in new IDs being assigned, complicating theft detection.
                    Solution: ByteTrack’s advanced mechanisms for handling unmatched detections were utilized to implement a re-identification strategy, ensuring persistent ID tracking even after interruptions.</li>
                <li><strong>Lag in Real-Time Detection:</strong> Challenge: Initial deployment with YOLOv11 large models caused lag, hindering real-time performance.
                    Solution: The system was optimized to strike a balance between detection speed and accuracy, ensuring smooth and efficient operation.</li>
            </ul>
        </section>


        <section>
            <h2>4. Product Design and Vision</h2>
            <p>The product design reflects a structured plan that outlines the vision for the project's deployment, even though final implementation details remain under development. This framework demonstrates that a cohesive and actionable approach has been conceptualized, ensuring the project remains aligned with its goals.</p>
            <p>On the user side, the design emphasizes accessibility and functionality through mobile and web applications. Features like registration, authentication, camera integration, and real-time alerts are tailored to offer a seamless and intuitive user experience.</p>
            <p>The server side showcases a scalable architecture, including middleware, processing servers, and storage layers, built to handle data efficiently and integrate AI-powered theft detection models. The modular setup ensures adaptability for future enhancements and growth.</p>
            <p>While deployment specifics are still being refined, the existing plan highlights the project's readiness to evolve into a robust, market-ready solution. This demonstrates not only the feasibility of the project but also its scalability and potential for impactful real-world application.</p>

            <div class="visuals">
                <img src="Guard_Vision_Product_Design_Map.png" alt="Product Vision Map.">
                <p>Caption: Product Vision Map.</p>
            </div>
        </section>

        <section>
            <h2>5. Project Management</h2>
            <p><strong>Role of Scrum Master:</strong></p>
            <ul>
                <li>Coordinated sprints and facilitated collaboration between individual and group tasks.</li>
                <li>Addressed roadblocks and ensured alignment with project goals.</li>
                <li>Maintained documentation of progress and resolutions.</li>
            </ul>
            <p><strong>Team Dynamics:</strong></p>
            <ul>
                <li>Group activities such as brainstorming sessions and retrospectives improved teamwork and innovation.</li>
                <li>Role-specific contributions ensured clear accountability and efficient workflows.</li>
            </ul>
        </section>


          <section>
            <h2>6. Technologies and Tools Used</h2>
            <p><strong>AI Models:</strong></p>
            <ul>
                <li>YOLOv11 small/large</li>
                <li>Others tested (DETR, DINO-R50, DINO-SwinL, YOLO V3/V5/V11, Faster R-CNN, ATSS, RetinaNET)</li>
            </ul>
            <p><strong>Tracking Algorithms:</strong></p>
            <ul>
                <li>Deep SORT</li>
                <li>ByteTrack</li>
            </ul>
            <p><strong>Tools:</strong></p>
            <ul>
                <li>GitHub</li>
                <li>Visual Studio</li>
                <li>Trello</li>
                <li>Discord</li>
            </ul>
            <p><strong>Notification System Integration:</strong></p>
            <ul>
                <li>Webhooks</li>
                <li>API-based notifications</li>
            </ul>
        </section>
        
        <section>
            <h2>7. Notification System Integration</h2>
            <p>Developed an API pipeline to link the AI detection model with a user notification system.</p>
            <p><strong>Features:</strong></p>
            <ul>
                <li>Smart notification triggers based on theft probability thresholds.</li>
                <li>Advanced filtering to minimize irrelevant alerts.</li>
            </ul>
            <p><strongTestingModule:</strong></p>
            <ul>
                <li>Simulated theft scenarios to validate system reliability and accuracy.</li>
            </ul>
        </section>
        
        <section>
            <h2>8. Use Cases and User Scenarios</h2>
            <p><strong>Potential Applications:</strong></p>
            <ul>
                <li>Residential gardens and front doors</li>
                <li>Small businesses with outdoor assets</li>
            </ul>
            <p><strong>Example Scenarios:</strong></p>
            <ul>
                <li>Alerting on unauthorized object removal or theft.</li>
                <li>Reducing irrelevant notifications caused by animals or passing vehicles.</li>
            </ul>
            <p><strong>User Benefits:</strong></p>
            <ul>
                <li>Fewer false alarms, leading to increased trust in the system (compared to traditional motion detection sensors).</li>
                <li>Real-time notifications ensure timely intervention.</li>
            </ul>
        </section>

        
        <section>
            <h2>9. Learning and Reflections</h2>
            <p><strong>Educational Value:</strong></p>
            <ul>
                <li>Hands-on experience in evaluating and integrating AI models.</li>
                <li>Practical exposure to resolving real-world challenges in tracking and notifications.</li>
                <li>Teamwork dynamics through a mix of individual and collaborative assignments.</li>
            </ul>
        </section>
        
        <section>
            <h2>10. Next Steps</h2>
            <p><strong>Refinement of Tracking Algorithms:</strong></p>
            <ul>
                <li>Fine-tuning the model with various datasets, including real, augmented, and generated visual data.</li>
            </ul>
            <p><strong>Testing:</strong></p>
            <ul>
                <li>Testing with diverse datasets to improve robustness.</li>
            </ul>
            <p><strong>Scalability and Commercialization:</strong></p>
            <ul>
                <li>Refinement of tracking algorithms and further optimization.</li>
                <li>Exploring future opportunities for scaling and commercialization.</li>
                <li>Deploying the model for access via cloud services for beta test case usage.</li>
            </ul>
        </section>

    </main>
    <footer>
        <p>&copy; 2025 Guard Vision Project</p>
    </footer>
</body>
</html>
